{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary Packages for this software to run\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'train_sortiert_new_format.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:  (16317, 2331)\n",
      "label: (16317,)\n"
     ]
    }
   ],
   "source": [
    "#split into target and data\n",
    "target = df['label_id']\n",
    "data = df.iloc[:,3:]\n",
    "print(\"data: \",data.shape)\n",
    "print(\"label:\", target.shape)\n",
    "\n",
    "#filter dataframe\n",
    "filtered_df = df[df['label_id'] != 20]\n",
    "\n",
    "#split into target and data\n",
    "target = filtered_df['label_id']\n",
    "data = filtered_df.iloc[:,3:]\n",
    "\n",
    "#split into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data,target,random_state=1,test_size=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 0.8083765112262522\n",
      "Test Set Accuracy: 0.7638121546961326\n"
     ]
    }
   ],
   "source": [
    "#Create Model\n",
    "clr_filtered = LogisticRegression(max_iter=2000, random_state=1)\n",
    "clr_filtered.fit(X_train, y_train)\n",
    "\n",
    "#predict training and new data\n",
    "y_train_pred = clr_filtered.predict(X_train) \n",
    "y_test_pred = clr_filtered.predict(X_test)\n",
    "\n",
    "#evaluation of the prediction\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Test Set Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Table\n",
    "df_columns = [] #'video_id', 'label_id', 'label']\n",
    "for frame in range(1,38):\n",
    "    for landmark in range (0,21):\n",
    "        s1 = f'{\"F\"}{frame}{\"_L\"}{landmark}{\"_X\"}'\n",
    "        s2 = f'{\"F\"}{frame}{\"_L\"}{landmark}{\"_Y\"}'\n",
    "        s3 = f'{\"F\"}{frame}{\"_L\"}{landmark}{\"_Z\"}'\n",
    "        df_columns.append(s1)\n",
    "        df_columns.append(s2)\n",
    "        df_columns.append(s3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Dataframe\n",
    "df = pd.DataFrame(columns=df_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_L0_X</th>\n",
       "      <th>F1_L0_Y</th>\n",
       "      <th>F1_L0_Z</th>\n",
       "      <th>F1_L1_X</th>\n",
       "      <th>F1_L1_Y</th>\n",
       "      <th>F1_L1_Z</th>\n",
       "      <th>F1_L2_X</th>\n",
       "      <th>F1_L2_Y</th>\n",
       "      <th>F1_L2_Z</th>\n",
       "      <th>F1_L3_X</th>\n",
       "      <th>...</th>\n",
       "      <th>F37_L17_Z</th>\n",
       "      <th>F37_L18_X</th>\n",
       "      <th>F37_L18_Y</th>\n",
       "      <th>F37_L18_Z</th>\n",
       "      <th>F37_L19_X</th>\n",
       "      <th>F37_L19_Y</th>\n",
       "      <th>F37_L19_Z</th>\n",
       "      <th>F37_L20_X</th>\n",
       "      <th>F37_L20_Y</th>\n",
       "      <th>F37_L20_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 2331 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [F1_L0_X, F1_L0_Y, F1_L0_Z, F1_L1_X, F1_L1_Y, F1_L1_Z, F1_L2_X, F1_L2_Y, F1_L2_Z, F1_L3_X, F1_L3_Y, F1_L3_Z, F1_L4_X, F1_L4_Y, F1_L4_Z, F1_L5_X, F1_L5_Y, F1_L5_Z, F1_L6_X, F1_L6_Y, F1_L6_Z, F1_L7_X, F1_L7_Y, F1_L7_Z, F1_L8_X, F1_L8_Y, F1_L8_Z, F1_L9_X, F1_L9_Y, F1_L9_Z, F1_L10_X, F1_L10_Y, F1_L10_Z, F1_L11_X, F1_L11_Y, F1_L11_Z, F1_L12_X, F1_L12_Y, F1_L12_Z, F1_L13_X, F1_L13_Y, F1_L13_Z, F1_L14_X, F1_L14_Y, F1_L14_Z, F1_L15_X, F1_L15_Y, F1_L15_Z, F1_L16_X, F1_L16_Y, F1_L16_Z, F1_L17_X, F1_L17_Y, F1_L17_Z, F1_L18_X, F1_L18_Y, F1_L18_Z, F1_L19_X, F1_L19_Y, F1_L19_Z, F1_L20_X, F1_L20_Y, F1_L20_Z, F2_L0_X, F2_L0_Y, F2_L0_Z, F2_L1_X, F2_L1_Y, F2_L1_Z, F2_L2_X, F2_L2_Y, F2_L2_Z, F2_L3_X, F2_L3_Y, F2_L3_Z, F2_L4_X, F2_L4_Y, F2_L4_Z, F2_L5_X, F2_L5_Y, F2_L5_Z, F2_L6_X, F2_L6_Y, F2_L6_Z, F2_L7_X, F2_L7_Y, F2_L7_Z, F2_L8_X, F2_L8_Y, F2_L8_Z, F2_L9_X, F2_L9_Y, F2_L9_Z, F2_L10_X, F2_L10_Y, F2_L10_Z, F2_L11_X, F2_L11_Y, F2_L11_Z, F2_L12_X, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 2331 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show Dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use MediaPipe to draw the hand framework over the top of hands it identifies\n",
    "drawingModule = mp.solutions.drawing_utils\n",
    "handsModule = mp.solutions.hands\n",
    "\n",
    "\n",
    "def extract_data(image):\n",
    "    # Use MediaPipe hand tracking with static_image_mode set to True\n",
    "    with handsModule.Hands(static_image_mode=True, min_detection_confidence=0.7, max_num_hands=1) as hands:\n",
    "        new_row=[]\n",
    "        j = 0\n",
    "        frame = cv2.resize(image, (640, 480))\n",
    "        \n",
    "        # Process the image and produce the hand framework overlay on top of the hand\n",
    "        results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # In case the system sees multiple hands, this if statement deals with that and produces another hand overlay\n",
    "        if results.multi_hand_landmarks:\n",
    "            for handLandmarks in results.multi_hand_landmarks:\n",
    "                drawingModule.draw_landmarks(frame, handLandmarks, handsModule.HAND_CONNECTIONS)\n",
    "                i = 0\n",
    "                last_idx = 0\n",
    "                for idx, landmark in enumerate(handLandmarks.landmark):\n",
    "                    while (i < idx):\n",
    "                        new_row.append(0)\n",
    "                        new_row.append(0)\n",
    "                        new_row.append(0)\n",
    "                        i = i+1\n",
    "\n",
    "                    new_row.append(landmark.x)\n",
    "                    new_row.append(landmark.y)\n",
    "                    new_row.append(landmark.z)\n",
    "                    i = idx+1\n",
    "                    last_idx = idx\n",
    "                if last_idx <= 20:\n",
    "                    for i in range(last_idx+1, 21):\n",
    "                        new_row.append(0)\n",
    "                        new_row.append(0)\n",
    "                        new_row.append(0)\n",
    "        \n",
    "        else:\n",
    "            for i in range (0,63):\n",
    "                new_row.append(0)\n",
    "            j = j+1\n",
    "        result = new_row.copy()\n",
    "        new_row.clear()\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wenni\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n",
      "[[9.742e+01 5.000e-01 0.000e+00 4.000e-02 9.000e-02 3.000e-02 1.430e+00\n",
      "  4.900e-01]]\n"
     ]
    }
   ],
   "source": [
    "images_dir = \"C:\\\\Users\\\\wenni\\\\BV-Projekt-Echtzeit-Handerkennung\\\\14zip\\\\14\"\n",
    "images = []\n",
    "for image in os.listdir(images_dir):\n",
    "    image_path = os.path.join(images_dir, image)\n",
    "    images.append(cv2.imread(image_path))\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "row_arr = []\n",
    "counter = 0\n",
    "n = 37\n",
    "\n",
    "for image in images:\n",
    "    # ret, frame = cap.read()\n",
    "    row_arr.extend(extract_data(image))\n",
    "    counter += 1\n",
    "    if counter > n:\n",
    "        del row_arr[0:63]\n",
    "    if counter == n:\n",
    "        # model anwenden\n",
    "        df.loc[0] = row_arr\n",
    "        y_prediction = clr_filtered.predict(df)\n",
    "        probabilities = clr_filtered.predict_proba(df)\n",
    "        probabilities_in_percent = np.round(probabilities * 100, 2)\n",
    "        print(y_prediction)\n",
    "        print(probabilities_in_percent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
