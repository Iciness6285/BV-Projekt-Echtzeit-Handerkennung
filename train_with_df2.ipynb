{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "file_path = 'train_sortiert_new_format.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into target and data\n",
    "target = df['label_id']\n",
    "data = df.iloc[:,3:]\n",
    "print(\"data: \",data.shape)\n",
    "print(\"label:\", target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data,target,random_state=1,test_size=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print shape\n",
    "print('X_train : ') \n",
    "print(X_train.shape) \n",
    "print('') \n",
    "print('X_test : ') \n",
    "print(X_test.shape) \n",
    "print('') \n",
    "print('y_train : ') \n",
    "print(y_train.shape) \n",
    "print('') \n",
    "print('y_test : ') \n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of training data\n",
    "\n",
    "# Get unique labels and their counts\n",
    "unique_labels, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "# Plotting\n",
    "plt.bar(unique_labels, counts)\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Number of Samples per Label')\n",
    "plt.show()\n",
    "\n",
    "# Print unique labels and their counts\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f\"Label '{label}': {count} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import training libraries\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "clr = LogisticRegression(max_iter=2000, random_state=1)\n",
    "clr.fit(X_train, y_train)\n",
    "\n",
    "#predict training and new data\n",
    "y_train_pred = clr.predict(X_train) \n",
    "y_test_pred = clr.predict(X_test)\n",
    "\n",
    "#evaluation of the prediction\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Test Set Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred, labels=clr.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=clr.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First impression:\n",
    "There seems to be an issue with label 20 \"Thumb Up\". Although the true label 20 is often correctly predicted as 20, many other classes are also predicted as label 20, although they belong to another label. Idea: leave out gesture 20, since it's not that relevant for our project.\n",
    "Additionally, also out training accuracy is too low. We should try to improve it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter dataframe\n",
    "filtered_df = df[df['label_id'] != 20]\n",
    "\n",
    "#split into target and data\n",
    "target = filtered_df['label_id']\n",
    "data = filtered_df.iloc[:,3:]\n",
    "\n",
    "#split into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data,target,random_state=1,test_size=0.2,shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Model\n",
    "clr_filtered = LogisticRegression(max_iter=2000, random_state=1)\n",
    "clr_filtered.fit(X_train, y_train)\n",
    "\n",
    "#predict training and new data\n",
    "y_train_pred = clr_filtered.predict(X_train) \n",
    "y_test_pred = clr_filtered.predict(X_test)\n",
    "\n",
    "#evaluation of the prediction\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Test Set Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the Confusion Matrix\n",
    "cm_filtered = confusion_matrix(y_test, y_test_pred, labels=clr_filtered.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_filtered,display_labels=clr_filtered.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: The filtered version didn't increase the training accuracy, but improved the test accuracy. I think it's worth to continue with the filtered version. \n",
    "\n",
    "Continue with an Neural Network (MLPClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize data\n",
    "scaler = StandardScaler()\n",
    "# Fit only on the training data\n",
    "scaler.fit(X_train)\n",
    "# Apply the transformations to the data\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an MLPClassifier\n",
    "\n",
    "hidden_layer_sizes = (600,100,50) #change sizes if necessary\n",
    "mlp = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = mlp.predict(X_test)\n",
    "y_pred_train = mlp.predict(X_train)\n",
    "\n",
    "#evaluation of the prediction\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(\"Training Set Accuracy\", train_accuracy)\n",
    "print(\"Test Set Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the Confusion Matrix\n",
    "cm_mlp = confusion_matrix(y_test, y_pred, labels=mlp.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_mlp,display_labels=mlp.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try to improve with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (100, 50)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.0001, 0.01],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "}\n",
    "\n",
    "# Create an MLPClassifier\n",
    "mlp2 = MLPClassifier(max_iter=1000, random_state=42)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(mlp, param_grid, cv=3, n_jobs=-1, verbose=3, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the results for each parameter setting\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "print(results_df[['params', 'mean_test_score', 'std_test_score', 'rank_test_score']])\n",
    "\n",
    "# Print the best parameters found by GridSearchCV\n",
    "print(\"\\nBest parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Use the best estimator to make predictions\n",
    "best_mlp = grid_search.best_estimator_\n",
    "y_test_pred = best_mlp.predict(X_test)\n",
    "\n",
    "#Evaluation of the prediction\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Set Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP Classifier doesn't seem to work very well, or the parameters are still not right adjusted. So let's try another Classifier.\n",
    "\n",
    "Use XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb for classification\n",
    "#model = xgb.XGBClassifier(\n",
    "#    objective='multi:softprob',\n",
    " #   num_class=num_classes,      \n",
    "  #  max_depth=max_depth,       \n",
    "   # learning_rate=learning_rate,\n",
    "    #subsample=subsample,        \n",
    "    #colsample_bytree=colsample, \n",
    "    #n_estimators=num_estimators\n",
    "#)\n",
    "\n",
    "cl_xgb3 = xgb.XGBClassifier(objective='multi:softprob', num_class=8, random_state=42, use_label_encoder=False, n_estimators=100)\n",
    "\n",
    "# Train the model\n",
    "cl_xgb3.fit(X_train, y_train_encoded)\n",
    "\n",
    "#predict training and new data\n",
    "y_train_pred = cl_xgb3.predict(X_train) \n",
    "y_test_pred = cl_xgb3.predict(X_test)\n",
    "\n",
    "#evaluation of the prediction\n",
    "train_accuracy = accuracy_score(y_train_encoded, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test_encoded, y_test_pred)\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Test Set Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the Confusion Matrix\n",
    "cm_xgb = confusion_matrix(y_test_encoded, y_test_pred, labels=cl_xgb3.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_xgb,display_labels=cl_xgb3.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy seems to increase. These are the best accuracy values so far. We should continue with techniques to reduce the dimensionality, since we have a lot of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try another version of xgboost with DMatrix (highly optimized class for memory and speed)\n",
    "\n",
    "# Create DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train_encoded, enable_categorical=True)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test_encoded, enable_categorical=True)\n",
    "\n",
    "# Define parameters\n",
    "params = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 8,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'eval_metric': 'mlogloss'\n",
    "}\n",
    "\n",
    "# Train the model, use more configurations\n",
    "bst = xgb.train(params, dtrain, num_boost_round=100, evals=[(dtest, 'test')], early_stopping_rounds=10)\n",
    "\n",
    "# Make predictions on both training and test sets\n",
    "train_preds = bst.predict(dtrain)\n",
    "test_preds = bst.predict(dtest)\n",
    "\n",
    "# Evaluate accuracy\n",
    "train_accuracy = accuracy_score(y_train_encoded, train_preds)\n",
    "test_accuracy = accuracy_score(y_test_encoded, test_preds)\n",
    "\n",
    "print(f\"Training set accuracy: {train_accuracy:.2f}\")\n",
    "print(f\"Test set accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selection technique one\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "#Select top k features based on ANOVA F-value\n",
    "selector = SelectKBest(score_func=f_classif, k=1000)  # Adjust k as needed\n",
    "\n",
    "# Fit selector on training data and transform it\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "X_test_selected = selector.transform(X_test)  # Transform test data using the same selector\n",
    "\n",
    "#test with xgboost\n",
    "cl_xgb2 = xgb.XGBClassifier(objective='multi:softmax', num_class=8, random_state=42, use_label_encoder=False)\n",
    "\n",
    "# Train the model\n",
    "cl_xgb2.fit(X_train_selected, y_train_encoded)\n",
    "\n",
    "#predict training and new data\n",
    "y_train_pred = cl_xgb2.predict(X_train_selected) \n",
    "y_test_pred = cl_xgb2.predict(X_test_selected)\n",
    "\n",
    "#evaluation of the prediction\n",
    "train_accuracy = accuracy_score(y_train_encoded, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test_encoded, y_test_pred)\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Test Set Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method decreases accuracy, so we should proceed with another technique. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to improve LogisticRegression again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_log = LogisticRegression(solver='saga', max_iter=2000, random_state=1)\n",
    "\n",
    "# Set up the hyperparameter grid\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1],\n",
    "    'penalty': ['l1', 'l2']  # SAGA supports both L1 and L2 regularization\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to search for the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=clf_log, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=3)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "\n",
    "# Train the model using the best hyperparameters\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "print(f\"Training Accuracy: {accuracy_train}\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Set Accuracy: {accuracy}\")\n",
    "\n",
    "#best: C:1 , penalty: l2, Accuracy: 0.774"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "clr = LogisticRegression(max_iter=2000, random_state=1)\n",
    "clr.fit(X_train, y_train)\n",
    "\n",
    "#predict training and new data\n",
    "y_test_pred = clr.predict(X_test)\n",
    "y_test_prob = clr.predict_proba(X_test)\n",
    "\n",
    "#evaluation of the prediction\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Set Accuracy:\", test_accuracy)\n",
    "\n",
    "for idx, (pred, prob) in enumerate(zip(y_test_pred, y_test_prob)):\n",
    "    print(\"pred:\",pred,\" prob:\",prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['label'].unique())\n",
    "print(df['label_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should proceed now with tuning the xgb model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
