{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zoech\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>label_id</th>\n",
       "      <th>label</th>\n",
       "      <th>F1_L0_X</th>\n",
       "      <th>F1_L0_Y</th>\n",
       "      <th>F1_L0_Z</th>\n",
       "      <th>F1_L1_X</th>\n",
       "      <th>F1_L1_Y</th>\n",
       "      <th>F1_L1_Z</th>\n",
       "      <th>F1_L2_X</th>\n",
       "      <th>...</th>\n",
       "      <th>F37_L17_Z</th>\n",
       "      <th>F37_L18_X</th>\n",
       "      <th>F37_L18_Y</th>\n",
       "      <th>F37_L18_Z</th>\n",
       "      <th>F37_L19_X</th>\n",
       "      <th>F37_L19_Y</th>\n",
       "      <th>F37_L19_Z</th>\n",
       "      <th>F37_L20_X</th>\n",
       "      <th>F37_L20_Y</th>\n",
       "      <th>F37_L20_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>11</td>\n",
       "      <td>Sliding Two Fingers Left</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100011</td>\n",
       "      <td>20</td>\n",
       "      <td>Thumb Up</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>11</td>\n",
       "      <td>Sliding Two Fingers Left</td>\n",
       "      <td>0.269611</td>\n",
       "      <td>0.937481</td>\n",
       "      <td>4.710461e-07</td>\n",
       "      <td>0.302779</td>\n",
       "      <td>0.850025</td>\n",
       "      <td>-0.027882</td>\n",
       "      <td>0.300107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100031</td>\n",
       "      <td>12</td>\n",
       "      <td>Sliding Two Fingers Right</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>19</td>\n",
       "      <td>Thumb Down</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2334 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   video_id  label_id                      label   F1_L0_X   F1_L0_Y  \\\n",
       "0      1000        11   Sliding Two Fingers Left  0.000000  0.000000   \n",
       "1    100011        20                   Thumb Up  0.000000  0.000000   \n",
       "2     10002        11   Sliding Two Fingers Left  0.269611  0.937481   \n",
       "3    100031        12  Sliding Two Fingers Right  0.000000  0.000000   \n",
       "4    100038        19                 Thumb Down  0.000000  0.000000   \n",
       "\n",
       "        F1_L0_Z   F1_L1_X   F1_L1_Y   F1_L1_Z   F1_L2_X  ...  F37_L17_Z  \\\n",
       "0  0.000000e+00  0.000000  0.000000  0.000000  0.000000  ...        0.0   \n",
       "1  0.000000e+00  0.000000  0.000000  0.000000  0.000000  ...        0.0   \n",
       "2  4.710461e-07  0.302779  0.850025 -0.027882  0.300107  ...        0.0   \n",
       "3  0.000000e+00  0.000000  0.000000  0.000000  0.000000  ...        0.0   \n",
       "4  0.000000e+00  0.000000  0.000000  0.000000  0.000000  ...        0.0   \n",
       "\n",
       "   F37_L18_X  F37_L18_Y  F37_L18_Z  F37_L19_X  F37_L19_Y  F37_L19_Z  \\\n",
       "0        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   F37_L20_X  F37_L20_Y  F37_L20_Z  \n",
       "0        0.0        0.0        0.0  \n",
       "1        0.0        0.0        0.0  \n",
       "2        0.0        0.0        0.0  \n",
       "3        0.0        0.0        0.0  \n",
       "4        0.0        0.0        0.0  \n",
       "\n",
       "[5 rows x 2334 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "file_path = 'train_sortiert_new_format.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into target and data\n",
    "target = df['label_id']\n",
    "data = df.iloc[:,3:]\n",
    "print(\"data: \",data.shape)\n",
    "print(\"label:\", target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data,target,random_state=1,test_size=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print shape\n",
    "print('X_train : ') \n",
    "print(X_train.shape) \n",
    "print('') \n",
    "print('X_test : ') \n",
    "print(X_test.shape) \n",
    "print('') \n",
    "print('y_train : ') \n",
    "print(y_train.shape) \n",
    "print('') \n",
    "print('y_test : ') \n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of training data\n",
    "\n",
    "# Get unique labels and their counts\n",
    "unique_labels, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "# Plotting\n",
    "plt.bar(unique_labels, counts)\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Number of Samples per Label')\n",
    "plt.show()\n",
    "\n",
    "# Print unique labels and their counts\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f\"Label '{label}': {count} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import training libraries\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "clr = LogisticRegression(max_iter=2000, random_state=1)\n",
    "clr.fit(X_train, y_train)\n",
    "\n",
    "#predict training and new data\n",
    "y_train_pred = clr.predict(X_train) \n",
    "y_test_pred = clr.predict(X_test)\n",
    "\n",
    "#evaluation of the prediction\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Test Set Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred, labels=clr.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=clr.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First impression:\n",
    "There seems to be an issue with label 20 \"Thumb Up\". Although the true label 20 is often correctly predicted as 20, many other classes are also predicted as label 20, although they belong to another label. Idea: leave out gesture 20, since it's not that relevant for our project.\n",
    "Additionally, also out training accuracy is too low. We should try to improve it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter dataframe\n",
    "filtered_df = df[df['label_id'] != 20]\n",
    "\n",
    "#split into target and data\n",
    "target = filtered_df['label_id']\n",
    "data = filtered_df.iloc[:,3:]\n",
    "\n",
    "#split into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data,target,random_state=1,test_size=0.2,shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Model\n",
    "clr_filtered = LogisticRegression(max_iter=2000, random_state=1)\n",
    "clr_filtered.fit(X_train, y_train)\n",
    "\n",
    "#predict training and new data\n",
    "y_train_pred = clr_filtered.predict(X_train) \n",
    "y_test_pred = clr_filtered.predict(X_test)\n",
    "\n",
    "#evaluation of the prediction\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Test Set Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the Confusion Matrix\n",
    "cm_filtered = confusion_matrix(y_test, y_test_pred, labels=clr_filtered.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_filtered,display_labels=clr_filtered.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: The filtered version didn't increase the training accuracy, but improved the test accuracy. I think it's worth to continue with the filtered version. \n",
    "\n",
    "Continue with an Neural Network (MLPClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize data\n",
    "scaler = StandardScaler()\n",
    "# Fit only on the training data\n",
    "scaler.fit(X_train)\n",
    "# Apply the transformations to the data\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an MLPClassifier\n",
    "\n",
    "hidden_layer_sizes = (600,100,50) #change sizes if necessary\n",
    "mlp = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = mlp.predict(X_test)\n",
    "y_pred_train = mlp.predict(X_train)\n",
    "\n",
    "#evaluation of the prediction\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(\"Training Set Accuracy\", train_accuracy)\n",
    "print(\"Test Set Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the Confusion Matrix\n",
    "cm_mlp = confusion_matrix(y_test, y_pred, labels=mlp.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_mlp,display_labels=mlp.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try to improve with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (100, 50)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.0001, 0.01],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "}\n",
    "\n",
    "# Create an MLPClassifier\n",
    "mlp2 = MLPClassifier(max_iter=1000, random_state=42)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(mlp, param_grid, cv=3, n_jobs=-1, verbose=3, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the results for each parameter setting\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "print(results_df[['params', 'mean_test_score', 'std_test_score', 'rank_test_score']])\n",
    "\n",
    "# Print the best parameters found by GridSearchCV\n",
    "print(\"\\nBest parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Use the best estimator to make predictions\n",
    "best_mlp = grid_search.best_estimator_\n",
    "y_test_pred = best_mlp.predict(X_test)\n",
    "\n",
    "#Evaluation of the prediction\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Set Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP Classifier doesn't seem to work very well, or the parameters are still not right adjusted. So let's try another Classifier.\n",
    "\n",
    "Use XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb for classification\n",
    "#model = xgb.XGBClassifier(\n",
    "#    objective='multi:softprob',\n",
    " #   num_class=num_classes,      \n",
    "  #  max_depth=max_depth,       \n",
    "   # learning_rate=learning_rate,\n",
    "    #subsample=subsample,        \n",
    "    #colsample_bytree=colsample, \n",
    "    #n_estimators=num_estimators\n",
    "#)\n",
    "\n",
    "cl_xgb3 = xgb.XGBClassifier(objective='multi:softprob', num_class=8, random_state=42, use_label_encoder=False, n_estimators=100)\n",
    "\n",
    "# Train the model\n",
    "cl_xgb3.fit(X_train, y_train_encoded)\n",
    "\n",
    "#predict training and new data\n",
    "y_train_pred = cl_xgb3.predict(X_train) \n",
    "y_test_pred = cl_xgb3.predict(X_test)\n",
    "\n",
    "#evaluation of the prediction\n",
    "train_accuracy = accuracy_score(y_train_encoded, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test_encoded, y_test_pred)\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Test Set Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the Confusion Matrix\n",
    "cm_xgb = confusion_matrix(y_test_encoded, y_test_pred, labels=cl_xgb3.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_xgb,display_labels=cl_xgb3.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy seems to increase. These are the best accuracy values so far. We should continue with techniques to reduce the dimensionality, since we have a lot of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try another version of xgboost with DMatrix (highly optimized class for memory and speed)\n",
    "\n",
    "# Create DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train_encoded, enable_categorical=True)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test_encoded, enable_categorical=True)\n",
    "\n",
    "# Define parameters\n",
    "params = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 8,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'eval_metric': 'mlogloss'\n",
    "}\n",
    "\n",
    "# Train the model, use more configurations\n",
    "bst = xgb.train(params, dtrain, num_boost_round=100, evals=[(dtest, 'test')], early_stopping_rounds=10)\n",
    "\n",
    "# Make predictions on both training and test sets\n",
    "train_preds = bst.predict(dtrain)\n",
    "test_preds = bst.predict(dtest)\n",
    "\n",
    "# Evaluate accuracy\n",
    "train_accuracy = accuracy_score(y_train_encoded, train_preds)\n",
    "test_accuracy = accuracy_score(y_test_encoded, test_preds)\n",
    "\n",
    "print(f\"Training set accuracy: {train_accuracy:.2f}\")\n",
    "print(f\"Test set accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selection technique one\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "#Select top k features based on ANOVA F-value\n",
    "selector = SelectKBest(score_func=f_classif, k=1000)  # Adjust k as needed\n",
    "\n",
    "# Fit selector on training data and transform it\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "X_test_selected = selector.transform(X_test)  # Transform test data using the same selector\n",
    "\n",
    "#test with xgboost\n",
    "cl_xgb2 = xgb.XGBClassifier(objective='multi:softmax', num_class=8, random_state=42, use_label_encoder=False)\n",
    "\n",
    "# Train the model\n",
    "cl_xgb2.fit(X_train_selected, y_train_encoded)\n",
    "\n",
    "#predict training and new data\n",
    "y_train_pred = cl_xgb2.predict(X_train_selected) \n",
    "y_test_pred = cl_xgb2.predict(X_test_selected)\n",
    "\n",
    "#evaluation of the prediction\n",
    "train_accuracy = accuracy_score(y_train_encoded, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test_encoded, y_test_pred)\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "print(\"Test Set Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method decreases accuracy, so we should proceed with another technique. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to improve LogisticRegression again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_log = LogisticRegression(solver='saga', max_iter=2000, random_state=1)\n",
    "\n",
    "# Set up the hyperparameter grid\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1],\n",
    "    'penalty': ['l1', 'l2']  # SAGA supports both L1 and L2 regularization\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to search for the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=clf_log, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=3)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "\n",
    "# Train the model using the best hyperparameters\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "print(f\"Training Accuracy: {accuracy_train}\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Set Accuracy: {accuracy}\")\n",
    "\n",
    "#best: C:1 , penalty: l2, Accuracy: 0.774"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{11: 'Sliding Two Fingers Left', 20: 'Thumb Up', 12: 'Sliding Two Fingers Right', 19: 'Thumb Down', 10: 'Sliding Two Fingers Down', 13: 'Sliding Two Fingers Up', 26: 'Zooming Out With Two Fingers', 5: 'Pushing Hand Away', 24: 'Zooming In With Two Fingers'}\n"
     ]
    }
   ],
   "source": [
    "label_mapping = dict(zip(df['label_id'].unique(), df['label'].unique()))\n",
    "print(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy: 0.774171270718232\n",
      "['11: 0.00%' '13: 0.00%' '13: 0.00%' ... '11: 0.00%' '24: 0.00%'\n",
      " '11: 0.13%']\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "clr = LogisticRegression(max_iter=2000, random_state=1)\n",
    "clr.fit(X_train, y_train)\n",
    "\n",
    "#predict training and new data\n",
    "y_test_pred = clr.predict(X_test)\n",
    "y_test_prob = clr.predict_proba(X_test)\n",
    "\n",
    "#evaluation of the prediction\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Set Accuracy:\", test_accuracy)\n",
    "\n",
    "#for idx, (pred, prob) in enumerate(zip(y_test_pred, y_test_prob)):\n",
    " #   print(\"pred:\",pred,\" prob:\",prob)\n",
    "output_array = np.empty((len(y_test_pred),), dtype='object')\n",
    "\n",
    "for i in range(len(y_test_pred)):\n",
    "    predicted_class = y_test_pred[i]\n",
    "    predicted_probability = y_test_prob[i, list(label_mapping.keys()).index(11)]\n",
    "    output_array[i] = f\"{predicted_class}: {predicted_probability*100:.2f}%\"\n",
    "\n",
    "print(output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_labels = np.array([label_mapping[label_id] for label_id in y_test_pred])\n",
    "result_table = np.column_stack((y_test_pred, y_test_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['11' 'Sliding Two Fingers Left']\n",
      " ['13' 'Sliding Two Fingers Up']\n",
      " ['13' 'Sliding Two Fingers Up']\n",
      " ...\n",
      " ['11' 'Sliding Two Fingers Left']\n",
      " ['24' 'Zooming In With Two Fingers']\n",
      " ['11' 'Sliding Two Fingers Left']]\n"
     ]
    }
   ],
   "source": [
    "print(result_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should proceed now with tuning the xgb model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
